{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing required libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pydantic in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.9.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests) (2024.6.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in d:\\users\\newac\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic) (4.12.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4 requests pydantic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 . importing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pydantic import BaseModel, HttpUrl\n",
    "from typing import Optional\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using pydantic BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Lesson(BaseModel):\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "    subject: str\n",
    "    material_type: str\n",
    "    description: Optional[str]\n",
    "    license_info: Optional[str]\n",
    "    keywords: Optional[str]\n",
    "    date_created: Optional[str]\n",
    "    resource_url: HttpUrl\n",
    "\n",
    "    def to_serializable(self):\n",
    "        \n",
    "        data = self.dict()\n",
    "        data['resource_url'] = str(self.resource_url)  # Ensure the URL is converted to string\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using Beautiful Soup for scraping data from Oercommons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://oercommons.org'\n",
    "search_url = 'https://oercommons.org/search?batch_size=20&sort_by=visits&view_mode=summary&f.general_subject=english-language-arts&f.sublevel=lower-primary'\n",
    "\n",
    "def scrape_lessons():\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    courses = soup.find_all('article', class_='js-index-item')\n",
    "    lesson_data = []\n",
    "\n",
    "    for course in courses:\n",
    "        try:\n",
    "            # Extract lesson details\n",
    "            title = course.find('div', class_='item-title').text.strip()\n",
    "            link = course.find('a', class_='item-link')['href']\n",
    "            author = course.find('dl').find_all('dd')[0].text.strip() if course.find('dl') else 'N/A'\n",
    "            subject = course.find('dl').find_all('dd')[1].text.strip() if course.find('dl') else 'N/A'\n",
    "            material_type = course.find('dl').find_all('dd')[2].text.strip() if course.find('dl') else 'N/A'\n",
    "            description = course.find('div', class_='abstract').text.strip() if course.find('div', 'abstract') else 'N/A'\n",
    "            license_info = course.find('div', class_='cou-bucket').text.strip() if course.find('div', 'cou-bucket') else 'N/A'\n",
    "\n",
    "            lesson_url = base_url + link\n",
    "            lesson_response = requests.get(lesson_url)\n",
    "            lesson_soup = BeautifulSoup(lesson_response.content, 'html.parser')\n",
    "\n",
    "            keywords = lesson_soup.find('meta', {'itemprop': 'keywords'})['content'] if lesson_soup.find('meta', {'itemprop': 'keywords'}) else 'N/A'\n",
    "            date_created = lesson_soup.find('meta', {'itemprop': 'dateCreated'})['content'] if lesson_soup.find('meta', {'itemprop': 'dateCreated'}) else 'N/A'\n",
    "            resource_url = lesson_soup.find('a', {'id': 'goto'})['href'] if lesson_soup.find('a', {'id': 'goto'}) else 'N/A'\n",
    "\n",
    "            # Create lesson object using Pydantic validation\n",
    "            lesson = Lesson(\n",
    "                title=title,\n",
    "                author=author,\n",
    "                subject=subject,\n",
    "                material_type=material_type,\n",
    "                description=description,\n",
    "                license_info=license_info,\n",
    "                keywords=keywords,\n",
    "                date_created=date_created,\n",
    "                resource_url=resource_url\n",
    "            )\n",
    "\n",
    "            lesson_data.append(lesson.to_serializable())  # Convert data for JSON serialization\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing lesson: {e}\")\n",
    "\n",
    "    return lesson_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating json file to save the scraped data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_data_to_json(data, file_name='lessons.json'):\n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(data, f, indent=4)  # Data is now serializable\n",
    "        print(f\"Data saved to {file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Finally Scraping data from OerCommons and saving it to json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping lessons...\n",
      "Saving data to JSON...\n",
      "Data saved to lessons.json\n"
     ]
    }
   ],
   "source": [
    "def run_etl():\n",
    "    print(\"Scraping lessons...\")\n",
    "    lessons = scrape_lessons()\n",
    "    \n",
    "    print(\"Saving data to JSON...\")\n",
    "    save_data_to_json(lessons)\n",
    "\n",
    "# Run the ETL process\n",
    "run_etl()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
